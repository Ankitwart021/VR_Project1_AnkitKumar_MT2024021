{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "k6GxOmVjJUwN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SAMPLES = 2000\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/1/face_crop\"\n",
        "mask_dir = \"/content/drive/MyDrive/1/face_crop_segmentation\"\n",
        "\n",
        "# Load and limit the number of samples\n",
        "image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))[:MAX_SAMPLES]\n",
        "mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.jpg\")))[:MAX_SAMPLES]\n"
      ],
      "metadata": {
        "id": "ilm2_nBVKMn2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "\n",
        "X, Y = [], []\n",
        "\n",
        "for img_path, mask_path in tqdm(zip(image_paths, mask_paths), total=len(image_paths)):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    mask = (mask > 127).astype(np.uint8)\n",
        "\n",
        "    X.append(img)\n",
        "    Y.append(mask)\n",
        "\n",
        "X = np.array(X) / 255.0\n",
        "Y = np.expand_dims(np.array(Y), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpXyoYxwKSxB",
        "outputId": "dce11ba0-b969-403c-a1cf-636f1bf12612"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:31<00:00, 63.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train/Validation split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3_vl4kZkKT8n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build U-Net model\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(16, 3, activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D()(c1)\n",
        "\n",
        "    c2 = Conv2D(32, 3, activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(32, 3, activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D()(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    b1 = Conv2D(64, 3, activation='relu', padding='same')(p2)\n",
        "    b1 = Conv2D(64, 3, activation='relu', padding='same')(b1)\n",
        "\n",
        "    # Decoder\n",
        "    u1 = UpSampling2D()(b1)\n",
        "    u1 = concatenate([u1, c2])\n",
        "    c3 = Conv2D(32, 3, activation='relu', padding='same')(u1)\n",
        "    c3 = Conv2D(32, 3, activation='relu', padding='same')(c3)\n",
        "\n",
        "    u2 = UpSampling2D()(c3)\n",
        "    u2 = concatenate([u2, c1])\n",
        "    c4 = Conv2D(16, 3, activation='relu', padding='same')(u2)\n",
        "    c4 = Conv2D(16, 3, activation='relu', padding='same')(c4)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(c4)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "r3ylzUcMKf6k"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train model\n",
        "model = build_unet((IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F05h4RL7Kg67",
        "outputId": "cba37561-0136-4e1c-c879-bb6b36340d7e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 2s/step - accuracy: 0.6860 - loss: 0.6027 - val_accuracy: 0.7784 - val_loss: 0.4586\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 2s/step - accuracy: 0.7723 - loss: 0.4708 - val_accuracy: 0.8063 - val_loss: 0.4251\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 2s/step - accuracy: 0.7947 - loss: 0.4431 - val_accuracy: 0.8081 - val_loss: 0.4217\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.8012 - loss: 0.4356 - val_accuracy: 0.8165 - val_loss: 0.4102\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.8038 - loss: 0.4267 - val_accuracy: 0.8245 - val_loss: 0.3921\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.8146 - loss: 0.4063 - val_accuracy: 0.8315 - val_loss: 0.3779\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.8202 - loss: 0.3980 - val_accuracy: 0.8372 - val_loss: 0.3687\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.8266 - loss: 0.3865 - val_accuracy: 0.8346 - val_loss: 0.3738\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.8314 - loss: 0.3790 - val_accuracy: 0.8358 - val_loss: 0.3661\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 2s/step - accuracy: 0.8333 - loss: 0.3715 - val_accuracy: 0.8452 - val_loss: 0.3536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model.predict(X_val)\n",
        "preds_bin = (preds > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "3Jpb1f9NcpaS",
        "outputId": "2683566b-2f92-464d-ae82-fc98382ae016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 995ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_iou(gt, pred):\n",
        "    intersection = np.logical_and(gt, pred)\n",
        "    union = np.logical_or(gt, pred)\n",
        "    return np.sum(intersection) / np.sum(union)\n",
        "\n",
        "def compute_dice(gt, pred):\n",
        "    intersection = np.sum(gt * pred)\n",
        "    return (2. * intersection) / (np.sum(gt) + np.sum(pred))\n",
        "\n",
        "ious, dices = [], []\n",
        "for gt, pred in zip(Y_val, preds_bin):\n",
        "    gt = gt.squeeze()\n",
        "    pred = pred.squeeze()\n",
        "    ious.append(compute_iou(gt, pred))\n",
        "    dices.append(compute_dice(gt, pred))\n",
        "\n",
        "print(f\"U-Net Average IoU: {np.mean(ious):.4f}\")\n",
        "print(f\"U-Net Average Dice Score: {np.mean(dices):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QkLn4Y9Kl_m",
        "outputId": "77243b46-2241-4110-9748-98f7d5842ab9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U-Net Average IoU: 0.6288\n",
            "U-Net Average Dice Score: 0.7517\n"
          ]
        }
      ]
    }
  ]
}